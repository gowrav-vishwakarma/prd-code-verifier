# AI Provider Configuration
# Set the default AI provider (openai, gemini, ollama, lm_studio)
DEFAULT_AI_PROVIDER=openai

# OpenAI Configuration
OPENAI_API_KEY=your_openai_api_key_here
OPENAI_BASE_URL=https://api.openai.com/v1
OPENAI_MODEL=gpt-3.5-turbo

# Google Gemini Configuration
GEMINI_API_KEY=your_gemini_api_key_here
GEMINI_MODEL=gemini-pro

# Ollama Configuration
OLLAMA_BASE_URL=http://localhost:11434
OLLAMA_MODEL=llama2

# LM Studio Configuration
LM_STUDIO_BASE_URL=http://localhost:1234/v1
LM_STUDIO_MODEL=local-model

# Application Configuration
DEBUG=True
HOST=0.0.0.0
PORT=8000

# Streaming Configuration
# Set to False to disable real-time streaming (faster for small responses)
ENABLE_STREAMING=True
